<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Champion Chat (Static)</title>
  <style>
    :root {
      --bg: #f3efe6;
      --panel: #fffaf0;
      --ink: #171717;
      --muted: #5e5a53;
      --line: #d8cfbf;
      --accent: #0f766e;
      --accent2: #b45309;
      --user: #e0f2fe;
      --bot: #eef2ff;
      --sys: #fef3c7;
      --shadow: rgba(23, 23, 23, 0.08);
    }
    * { box-sizing: border-box; }
    body {
      margin: 0;
      font-family: Georgia, "Times New Roman", serif;
      color: var(--ink);
      background:
        radial-gradient(circle at 10% 10%, rgba(180,83,9,.12), transparent 40%),
        radial-gradient(circle at 90% 15%, rgba(15,118,110,.10), transparent 45%),
        linear-gradient(180deg, #f7f2e9 0%, #f2ede3 100%);
      min-height: 100vh;
    }
    .wrap {
      max-width: 1000px;
      margin: 0 auto;
      padding: 18px;
      display: grid;
      gap: 12px;
    }
    .card {
      background: var(--panel);
      border: 1px solid var(--line);
      border-radius: 14px;
      box-shadow: 0 8px 24px var(--shadow);
    }
    .header {
      padding: 14px 16px;
      display: flex;
      gap: 10px;
      align-items: baseline;
      justify-content: space-between;
    }
    .title {
      margin: 0;
      font-size: 1.2rem;
      letter-spacing: .02em;
    }
    .subtitle {
      color: var(--muted);
      font-size: .9rem;
    }
    .controls {
      padding: 14px 16px;
      border-top: 1px solid var(--line);
      display: grid;
      gap: 12px;
    }
    .row {
      display: grid;
      gap: 8px;
      grid-template-columns: 1fr;
    }
    .row.inline {
      grid-template-columns: 1fr auto auto auto auto;
      align-items: center;
    }
    label {
      font-size: .84rem;
      color: var(--muted);
    }
    input[type="text"], select, button, textarea {
      font: inherit;
    }
    input[type="text"], select {
      width: 100%;
      padding: 9px 10px;
      border: 1px solid var(--line);
      background: #fff;
      border-radius: 10px;
      color: var(--ink);
    }
    input[type="file"] {
      font-size: .9rem;
    }
    button {
      border: 1px solid var(--line);
      border-radius: 10px;
      background: white;
      padding: 8px 12px;
      cursor: pointer;
    }
    button.primary {
      background: var(--accent);
      border-color: var(--accent);
      color: white;
    }
    button:hover { filter: brightness(.98); }
    .status {
      margin: 0;
      padding: 10px 12px;
      border-top: 1px solid var(--line);
      background: #fff;
      border-radius: 0 0 14px 14px;
      font-size: .9rem;
      color: var(--muted);
    }
    .status.ok { color: #065f46; }
    .status.warn { color: #92400e; }
    .status.err { color: #991b1b; }
    .load-progress {
      border: 1px solid var(--line);
      border-radius: 10px;
      background: #fff;
      padding: 8px 10px;
      display: grid;
      gap: 6px;
    }
    .load-progress-head {
      display: flex;
      justify-content: space-between;
      gap: 8px;
      align-items: center;
      font-size: .82rem;
      color: var(--muted);
    }
    .load-progress-head strong {
      color: var(--ink);
      font-weight: 600;
    }
    .load-progress progress {
      width: 100%;
      height: 12px;
      accent-color: var(--accent);
    }
    .load-progress-text {
      font-size: .8rem;
      color: var(--muted);
      min-height: 1.1em;
    }
    .chat {
      display: grid;
      grid-template-rows: 1fr auto;
      min-height: 62vh;
    }
    .messages {
      padding: 14px;
      display: grid;
      gap: 10px;
      align-content: start;
      overflow-y: auto;
      max-height: 62vh;
    }
    .msg {
      border: 1px solid var(--line);
      border-radius: 12px;
      padding: 9px 10px;
      background: #fff;
      white-space: pre-wrap;
      line-height: 1.35;
    }
    .msg.user { background: var(--user); }
    .msg.bot { background: var(--bot); }
    .msg.sys { background: var(--sys); color: #78350f; }
    .msg .meta {
      display: block;
      margin-bottom: 4px;
      font-size: .78rem;
      color: var(--muted);
      text-transform: uppercase;
      letter-spacing: .06em;
    }
    .composer {
      border-top: 1px solid var(--line);
      padding: 12px;
      display: grid;
      gap: 8px;
    }
    .composer-grid {
      display: grid;
      grid-template-columns: 1fr auto;
      gap: 8px;
    }
    textarea {
      width: 100%;
      min-height: 72px;
      max-height: 180px;
      resize: vertical;
      border: 1px solid var(--line);
      border-radius: 10px;
      padding: 10px;
      background: white;
      color: var(--ink);
    }
    .footnote {
      font-size: .82rem;
      color: var(--muted);
    }
    .hidden {
      display: none !important;
    }
    details {
      border-top: 1px dashed var(--line);
      padding-top: 8px;
    }
    summary {
      cursor: pointer;
      color: var(--muted);
      font-size: .85rem;
    }
    #topCandidates {
      margin-top: 8px;
      font-size: .84rem;
      display: grid;
      gap: 6px;
    }
    .cand {
      border: 1px solid var(--line);
      border-radius: 8px;
      padding: 6px 8px;
      background: #fff;
    }
    .cand code {
      color: var(--accent2);
      font-size: .75rem;
    }
    @media (max-width: 780px) {
      .row.inline {
        grid-template-columns: 1fr 1fr;
      }
      .composer-grid {
        grid-template-columns: 1fr;
      }
    }
  </style>
</head>
<body>
  <div class="wrap">
    <section class="card">
      <div class="header">
        <div>
          <h1 class="title">Champion Chat (Web Interface)</h1>
          <div class="subtitle">Use browser metadata mode or connect to a full-model Flask API backend</div>
        </div>
      </div>
      <div class="controls">
        <div class="row">
          <label for="runMode">Run Mode</label>
          <select id="runMode">
            <option value="static" selected>Static Metadata (GitHub Pages)</option>
            <option value="onnx">Browser ONNX (Full Weights on Device)</option>
            <option value="api">Full Model API (Flask backend)</option>
          </select>
        </div>
        <div id="staticMetaUrlRow" class="row">
          <label for="metaUrl">Metadata JSON URL (same folder on GitHub Pages is easiest)</label>
          <input id="metaUrl" type="text" value="chat_model_meta_supermix_v27_500k.browser.json">
        </div>
        <div id="staticMetaFileRow" class="row">
          <label for="metaFile">Or load metadata JSON from your device</label>
          <input id="metaFile" type="file" accept=".json,application/json">
        </div>
        <div id="onnxModelUrlRow" class="row hidden">
          <label for="onnxModelUrl">ONNX model URL (full weights, browser inference)</label>
          <input id="onnxModelUrl" type="text" value="champion_model_chat_supermix_v27_500k_ft.onnx">
        </div>
        <div id="onnxModelFileRow" class="row hidden">
          <label for="onnxModelFile">Or load ONNX model from your device</label>
          <input id="onnxModelFile" type="file" accept=".onnx,application/octet-stream">
        </div>
        <div id="onnxMetaUrlRow" class="row hidden">
          <label for="onnxMetaUrl">Full metadata JSON URL (needs buckets + vec/ctx_vec)</label>
          <input id="onnxMetaUrl" type="text" value="chat_model_meta_supermix_v27_500k.json">
        </div>
        <div id="onnxMetaFileRow" class="row hidden">
          <label for="onnxMetaFile">Or load full metadata JSON from your device</label>
          <input id="onnxMetaFile" type="file" accept=".json,application/json">
        </div>
        <div id="apiBaseRow" class="row hidden">
          <label for="apiBaseUrl">Flask API Base URL (for example https://your-backend.example.com or http://127.0.0.1:8000)</label>
          <input id="apiBaseUrl" type="text" value="http://127.0.0.1:8000">
        </div>
        <div id="apiWeightsRow" class="row hidden">
          <label for="apiWeights">Weights path on the backend host (.pth)</label>
          <input id="apiWeights" type="text" value="champion_model_chat_supermix_v27_500k_ft.pth">
        </div>
        <div id="apiMetaRow" class="row hidden">
          <label for="apiMeta">Metadata path on the backend host (.json)</label>
          <input id="apiMeta" type="text" value="chat_model_meta_supermix_v27_500k.json">
        </div>
        <div class="row inline">
          <select id="styleMode" title="Style mode">
            <option value="auto">Style: auto</option>
            <option value="balanced">Style: balanced</option>
            <option value="concise">Style: concise</option>
            <option value="analyst">Style: analyst</option>
            <option value="creative">Style: creative</option>
          </select>
          <select id="creativity" title="Creativity">
            <option value="0.0">Creativity 0.0</option>
            <option value="0.25">Creativity 0.25</option>
            <option value="0.5" selected>Creativity 0.5</option>
            <option value="0.75">Creativity 0.75</option>
            <option value="1.0">Creativity 1.0</option>
          </select>
          <select id="topK" title="Top K">
            <option value="20">Pool 20</option>
            <option value="40" selected>Pool 40</option>
            <option value="80">Pool 80</option>
            <option value="160">Pool 160</option>
          </select>
          <button id="loadBtn" class="primary">Load Metadata</button>
          <button id="clearBtn">Clear Chat</button>
        </div>
        <div id="apiTuneRow" class="row inline hidden">
          <select id="apiResponseTemp" title="Response temperature">
            <option value="0.0">Temp 0.00</option>
            <option value="0.04">Temp 0.04</option>
            <option value="0.08" selected>Temp 0.08</option>
            <option value="0.15">Temp 0.15</option>
            <option value="0.25">Temp 0.25</option>
          </select>
          <select id="apiShowTop" title="Top candidate debug">
            <option value="0" selected>Debug top 0</option>
            <option value="3">Debug top 3</option>
            <option value="5">Debug top 5</option>
            <option value="8">Debug top 8</option>
          </select>
        </div>
        <div class="footnote">
          <span id="modeNote">Static browser mode uses the metadata JSON only. PyTorch <code>.pth</code> weights do not run on GitHub Pages.</span>
        </div>
        <div id="loadProgressWrap" class="row hidden">
          <div class="load-progress" aria-live="polite">
            <div class="load-progress-head">
              <strong id="loadProgressLabel">Loading...</strong>
              <span id="loadProgressPct">0%</span>
            </div>
            <progress id="loadProgress" max="1" value="0"></progress>
            <div id="loadProgressText" class="load-progress-text"></div>
          </div>
        </div>
      </div>
      <p id="status" class="status warn">Load a metadata JSON file to start.</p>
    </section>

    <section class="card chat">
      <div id="messages" class="messages"></div>
      <div class="composer">
        <div class="composer-grid">
          <textarea id="userInput" placeholder="Type a message..."></textarea>
          <button id="sendBtn" class="primary">Send</button>
        </div>
        <details>
          <summary>Top candidates (debug)</summary>
          <div id="topCandidates"></div>
        </details>
      </div>
    </section>
  </div>

  <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/blakejs@1.2.1/blake2b.min.js"></script>
  <script src="chat_feature_ctxv2.generated.js"></script>
  <script>
    const state = {
      meta: null,
      candidates: [],
      history: [],
      recentAssistant: [],
      loading: false,
      apiSessionId: (self.crypto && crypto.randomUUID) ? crypto.randomUUID() : `sess-${Date.now()}-${Math.floor(Math.random() * 1e6)}`,
      onnxSession: null,
      onnxMetaRaw: null,
      onnxModelSource: '',
      onnxFeatureMode: 'context_v2'
    };

    const els = {
      runMode: document.getElementById('runMode'),
      metaUrl: document.getElementById('metaUrl'),
      metaFile: document.getElementById('metaFile'),
      onnxModelUrl: document.getElementById('onnxModelUrl'),
      onnxModelFile: document.getElementById('onnxModelFile'),
      onnxMetaUrl: document.getElementById('onnxMetaUrl'),
      onnxMetaFile: document.getElementById('onnxMetaFile'),
      apiBaseUrl: document.getElementById('apiBaseUrl'),
      apiWeights: document.getElementById('apiWeights'),
      apiMeta: document.getElementById('apiMeta'),
      apiResponseTemp: document.getElementById('apiResponseTemp'),
      apiShowTop: document.getElementById('apiShowTop'),
      staticMetaUrlRow: document.getElementById('staticMetaUrlRow'),
      staticMetaFileRow: document.getElementById('staticMetaFileRow'),
      onnxModelUrlRow: document.getElementById('onnxModelUrlRow'),
      onnxModelFileRow: document.getElementById('onnxModelFileRow'),
      onnxMetaUrlRow: document.getElementById('onnxMetaUrlRow'),
      onnxMetaFileRow: document.getElementById('onnxMetaFileRow'),
      apiBaseRow: document.getElementById('apiBaseRow'),
      apiWeightsRow: document.getElementById('apiWeightsRow'),
      apiMetaRow: document.getElementById('apiMetaRow'),
      apiTuneRow: document.getElementById('apiTuneRow'),
      modeNote: document.getElementById('modeNote'),
      loadProgressWrap: document.getElementById('loadProgressWrap'),
      loadProgress: document.getElementById('loadProgress'),
      loadProgressLabel: document.getElementById('loadProgressLabel'),
      loadProgressPct: document.getElementById('loadProgressPct'),
      loadProgressText: document.getElementById('loadProgressText'),
      loadBtn: document.getElementById('loadBtn'),
      clearBtn: document.getElementById('clearBtn'),
      status: document.getElementById('status'),
      messages: document.getElementById('messages'),
      userInput: document.getElementById('userInput'),
      sendBtn: document.getElementById('sendBtn'),
      topCandidates: document.getElementById('topCandidates'),
      styleMode: document.getElementById('styleMode'),
      creativity: document.getElementById('creativity'),
      topK: document.getElementById('topK')
    };

    const STOPWORDS = new Set([
      'the','a','an','and','or','but','if','then','so','to','of','in','on','for','with','at','by',
      'is','it','this','that','these','those','i','you','we','they','he','she','me','my','your','our',
      'be','am','are','was','were','do','does','did','can','could','would','should','will','just'
    ]);
    const TEMPLATE_BANNED = [
      /build a builder angle/i,
      /the for case for whether/i,
      /\[reflective-set\d+\]/i,
      /decision policy framing/i
    ];

    function setStatus(text, kind = 'warn') {
      els.status.textContent = text;
      els.status.className = `status ${kind}`;
    }

    function formatBytes(n) {
      const x = Number(n);
      if (!Number.isFinite(x) || x < 0) return '? B';
      if (x < 1024) return `${Math.round(x)} B`;
      const units = ['KB', 'MB', 'GB'];
      let v = x / 1024;
      let i = 0;
      while (v >= 1024 && i < units.length - 1) {
        v /= 1024;
        i++;
      }
      return `${v.toFixed(v >= 100 ? 0 : v >= 10 ? 1 : 2)} ${units[i]}`;
    }

    function showLoadProgress() {
      setHidden(els.loadProgressWrap, false);
    }

    function hideLoadProgress() {
      if (!els.loadProgressWrap) return;
      els.loadProgress.max = 1;
      els.loadProgress.value = 0;
      els.loadProgressPct.textContent = '0%';
      els.loadProgressLabel.textContent = 'Loading...';
      els.loadProgressText.textContent = '';
      setHidden(els.loadProgressWrap, true);
    }

    function setLoadProgress({ label, fraction, detail, indeterminate = false }) {
      showLoadProgress();
      if (label) els.loadProgressLabel.textContent = label;
      if (indeterminate) {
        els.loadProgress.removeAttribute('value');
        els.loadProgress.max = 1;
        els.loadProgressPct.textContent = '...';
      } else {
        const f = Math.max(0, Math.min(1, Number(fraction) || 0));
        els.loadProgress.max = 1;
        els.loadProgress.value = f;
        els.loadProgressPct.textContent = `${Math.round(f * 100)}%`;
      }
      els.loadProgressText.textContent = detail || '';
    }

    function setPhaseByteProgress(label, loaded, total, startFrac, endFrac) {
      const hasTotal = Number.isFinite(total) && total > 0;
      if (!hasTotal) {
        setLoadProgress({
          label,
          fraction: startFrac,
          detail: `${formatBytes(loaded)} loaded`,
          indeterminate: true
        });
        return;
      }
      const phaseFrac = Math.max(0, Math.min(1, (Number(loaded) || 0) / total));
      const span = Math.max(0, endFrac - startFrac);
      const overallFrac = startFrac + phaseFrac * span;
      setLoadProgress({
        label,
        fraction: overallFrac,
        detail: `${formatBytes(loaded)} / ${formatBytes(total)}`
      });
    }

    function isApiMode() {
      return els.runMode.value === 'api';
    }

    function isOnnxMode() {
      return els.runMode.value === 'onnx';
    }

    function setHidden(el, hidden) {
      if (!el) return;
      el.classList.toggle('hidden', !!hidden);
    }

    function normalizedApiBase() {
      const base = String(els.apiBaseUrl.value || '').trim().replace(/\/+$/, '');
      if (!base) throw new Error('Enter a Flask API base URL first.');
      return base;
    }

    function apiUrl(path) {
      return `${normalizedApiBase()}${path}`;
    }

    async function apiJson(url, init) {
      const res = await fetch(url, init);
      let data = null;
      try { data = await res.json(); } catch (_) {}
      if (!res.ok || !data || data.ok === false) {
        const msg = (data && data.error) ? data.error : `HTTP ${res.status}`;
        throw new Error(msg);
      }
      return data;
    }

    function applyModeUI() {
      const api = isApiMode();
      const onnx = isOnnxMode();
      setHidden(els.staticMetaUrlRow, api || onnx);
      setHidden(els.staticMetaFileRow, api || onnx);
      setHidden(els.onnxModelUrlRow, !onnx);
      setHidden(els.onnxModelFileRow, !onnx);
      setHidden(els.onnxMetaUrlRow, !onnx);
      setHidden(els.onnxMetaFileRow, !onnx);
      setHidden(els.apiBaseRow, !api);
      setHidden(els.apiWeightsRow, !api);
      setHidden(els.apiMetaRow, !api);
      setHidden(els.apiTuneRow, !api);
      els.creativity.classList.toggle('hidden', api);
      els.topK.classList.toggle('hidden', api);
      els.loadBtn.textContent = api ? 'Load Full Model' : (onnx ? 'Load Browser ONNX' : 'Load Metadata');
      els.modeNote.innerHTML = api
        ? 'Full model API mode calls a separate Flask/PyTorch backend. GitHub Pages hosts only the interface.'
        : (onnx
          ? 'Browser ONNX mode runs the exported model weights on the user device with onnxruntime-web and a JS context_v2 encoder.'
          : 'Static browser mode uses the metadata JSON only. PyTorch <code>.pth</code> weights do not run on GitHub Pages.');
      if (!state.loading) {
        setStatus(
          api
            ? 'Full Model API mode selected. Set API URL, weights/meta paths, then click Load Full Model.'
            : (onnx
              ? 'Browser ONNX mode selected. Load the ONNX model and full metadata JSON, then chat locally in your browser.'
              : 'Load a metadata JSON file to start.'),
          'warn'
        );
      }
      els.topCandidates.innerHTML = '';
    }

    function addMessage(role, text) {
      const box = document.createElement('div');
      box.className = `msg ${role}`;
      const meta = document.createElement('span');
      meta.className = 'meta';
      meta.textContent = role === 'user' ? 'You' : role === 'bot' ? 'Bot' : 'System';
      box.appendChild(meta);
      box.appendChild(document.createTextNode(text));
      els.messages.appendChild(box);
      els.messages.scrollTop = els.messages.scrollHeight;
    }

    function clearChatUI() {
      state.history = [];
      state.recentAssistant = [];
      els.messages.innerHTML = '';
      els.topCandidates.innerHTML = '';
      addMessage('sys', 'Chat cleared.');
    }

    function normalizeMeta(raw) {
      if (!raw || typeof raw !== 'object') throw new Error('Invalid metadata JSON');
      let candidates = [];
      let labelPriors = {};
      const bucketsByLabel = {};
      const availableLabels = [];
      const featureMode = String(raw.feature_mode || raw.source_meta?.feature_mode || '').trim();
      const modelSize = String(raw.model_size || raw.source_meta?.model_size || '').trim();

      if (Array.isArray(raw.candidates)) {
        candidates = raw.candidates
          .map(r => ({
            label: String(r.label ?? ''),
            text: String(r.text ?? '').trim(),
            count: Number.isFinite(Number(r.count)) ? Number(r.count) : 1
          }))
          .filter(r => r.text);
        labelPriors = raw.label_priors || {};
      } else if (raw.buckets && typeof raw.buckets === 'object') {
        labelPriors = raw.label_priors || {};
        for (const [label, rows] of Object.entries(raw.buckets)) {
          if (!Array.isArray(rows)) continue;
          const labelNum = Number(label);
          if (Number.isFinite(labelNum)) availableLabels.push(labelNum);
          const normRows = [];
          for (const row of rows) {
            if (!row || typeof row !== 'object') continue;
            const text = String(row.text || '').trim();
            if (!text) continue;
            const normRow = {
              label: String(label),
              text,
              count: Number.isFinite(Number(row.count)) ? Number(row.count) : 1,
              vec: Array.isArray(row.vec) ? row.vec : undefined,
              ctx_vec: Array.isArray(row.ctx_vec) ? row.ctx_vec : undefined
            };
            candidates.push(normRow);
            normRows.push(normRow);
          }
          bucketsByLabel[String(label)] = normRows;
        }
      } else {
        throw new Error('Metadata JSON missing candidates/buckets');
      }

      return {
        raw,
        candidates,
        labelPriors,
        bucketsByLabel,
        availableLabels: availableLabels.length ? Array.from(new Set(availableLabels)).sort((a,b)=>a-b) : null,
        featureMode,
        modelSize,
        stats: {
          candidateCount: candidates.length,
          bucketCount: new Set(candidates.map(c => c.label)).size
        }
      };
    }

    function tokens(text) {
      return String(text || '').toLowerCase().match(/[a-z0-9_']+/g) || [];
    }

    function contentTokens(text) {
      return tokens(text).filter(t => t.length > 1 && !STOPWORDS.has(t));
    }

    function tokenSet(text) {
      return new Set(contentTokens(text));
    }

    function bigrams(text) {
      const t = contentTokens(text);
      const out = new Set();
      for (let i = 0; i < t.length - 1; i++) out.add(`${t[i]} ${t[i+1]}`);
      return out;
    }

    function jaccard(a, b) {
      if (!a.size && !b.size) return 0;
      let inter = 0;
      for (const x of a) if (b.has(x)) inter++;
      const union = a.size + b.size - inter;
      return union ? inter / union : 0;
    }

    function overlapRatio(a, b) {
      if (!a.size) return 0;
      let inter = 0;
      for (const x of a) if (b.has(x)) inter++;
      return inter / Math.max(1, a.size);
    }

    function inferStyleMode(query, selected) {
      if (selected && selected !== 'auto') return selected;
      const q = String(query || '').toLowerCase();
      if (/\b(short|brief|quick|tldr|one line)\b/.test(q)) return 'concise';
      if (/\b(step by step|debug|diagnose|tradeoff|explain why|analy[sz]e)\b/.test(q)) return 'analyst';
      if (/\b(creative|brainstorm|story|metaphor|analogy|imagine)\b/.test(q)) return 'creative';
      return 'balanced';
    }

    function detectDomains(text) {
      const q = String(text || '').toLowerCase();
      return {
        code: /```|traceback|python|javascript|typescript|api|sql|bug|error|exception|model|train/.test(q),
        science: /\b(science|physics|chemistry|biology|experiment|hypothesis|atom|molecule)\b/.test(q),
        math: /\b(math|algebra|equation|calculate|fraction|percent|solve)\b/.test(q) || /[0-9]+\s*[+\-*/=%]/.test(q),
        english: /\b(grammar|punctuation|rewrite|proofread|essay|sentence|paragraph)\b/.test(q),
        scripture: /\b(bible|scripture|verse|psalm|kjv|gospel|john|matthew)\b/.test(q),
        dictionary: /\b(define|definition|meaning|synonym|antonym|etymology|part of speech)\b/.test(q),
        literary: /\b(book|novel|character|theme|tone|literary|chapter|finnegans|joyce)\b/.test(q)
      };
    }

    function detectSmallTalk(query) {
      const q = String(query || '').trim().toLowerCase();
      if (!q) return null;
      if (/^(hi|hey|hello|yo|sup|good (morning|afternoon|evening))([!. ]*)$/.test(q)) {
        return 'Hi. What do you want help with: coding, writing, debugging, studying, or something else?';
      }
      if (/^(thanks|thank you|thx)([!. ]*)$/.test(q)) {
        return 'You’re welcome.';
      }
      if (/^(sorry|sorry\?|my bad|oops)([!. ]*)$/.test(q)) {
        return 'No problem. Do you want me to clarify the last answer or answer a new question?';
      }
      if (/^how can you help me([?.!]*)$/.test(q) || /^what can you do([?.!]*)$/.test(q)) {
        return 'I can help with coding, debugging, explanations, writing, study questions, and step-by-step problem solving. Ask something specific and I’ll answer directly.';
      }
      if (/^(what\?|huh\?|sorry\?\s*what)/.test(q)) {
        return 'I can clarify. Tell me which part was unclear, or paste the exact line you want explained.';
      }
      return null;
    }

    function isTemplateArtifact(text) {
      return TEMPLATE_BANNED.some(re => re.test(text || ''));
    }

    function styleAdjust(text, query, mode, creativity) {
      let out = String(text || '').trim();
      if (!out) return out;

      if (mode === 'concise') {
        const first = (out.match(/[^.!?]+[.!?]?/) || [out])[0].trim();
        const words = first.split(/\s+/);
        out = words.length > 28 ? words.slice(0, 28).join(' ').replace(/[,:;]+$/, '') + '.' : first;
        return out;
      }

      if (mode === 'analyst') {
        if (!/^\s*(1[\).]|first\b)/i.test(out)) {
          const parts = out.match(/[^.!?]+[.!?]?/g) || [out];
          if (parts.length >= 2) out = `1) ${parts[0].trim()} 2) ${parts[1].trim()}`;
          else out = `1) ${out}`;
        }
        return out;
      }

      if (mode === 'creative' && creativity > 0.35) {
        if (!/^(Creative take:|Fresh angle:|Idea sketch:|Consider this perspective:)/i.test(out)) {
          const intros = [
            'Fresh angle:',
            'Creative take:',
            'Idea sketch:',
            'Consider this perspective:'
          ];
          const pick = intros[Math.floor(Math.random() * intros.length)];
          out = `${pick} ${out}`;
        }
      }
      return out;
    }

    function renderTopCandidates(items) {
      els.topCandidates.innerHTML = '';
      for (const row of items) {
        const div = document.createElement('div');
        div.className = 'cand';
        const preview = row.text.length > 220 ? row.text.slice(0, 220) + '...' : row.text;
        const score = Number.isFinite(Number(row.score)) ? Number(row.score) : 0;
        const bits = [`score=${score.toFixed(3)}`];
        if (row.label !== undefined) bits.push(`label=${row.label}`);
        if (row.count !== undefined) bits.push(`count=${row.count}`);
        div.innerHTML = `<code>${bits.join(' ')}</code><div>${escapeHtml(preview)}</div>`;
        els.topCandidates.appendChild(div);
      }
    }

    function escapeHtml(s) {
      return String(s)
        .replace(/&/g, '&amp;')
        .replace(/</g, '&lt;')
        .replace(/>/g, '&gt;')
        .replace(/\"/g, '&quot;');
    }

    function rankCandidates(query, sourceCandidates = null) {
      const q = String(query || '').trim();
      const qTokens = tokenSet(q);
      const qBigrams = bigrams(q);
      const historyText = state.history.slice(-4)
        .map(turn => `user: ${turn.user}\nassistant: ${turn.bot}`)
        .join('\n');
      const ctxTokens = tokenSet(historyText + '\n' + q);
      const qDomains = detectDomains(q);
      const genericShort = qTokens.size <= 4;
      const recentSet = new Set(state.recentAssistant.slice(-3).map(s => String(s).trim()).filter(Boolean));

      const scored = [];
      const candidateSource = Array.isArray(sourceCandidates) ? sourceCandidates : state.candidates;
      for (const c of candidateSource) {
        const text = c.text;
        const tSet = tokenSet(text);
        if (!tSet.size) continue;
        const bSet = bigrams(text);

        const qOverlap = overlapRatio(qTokens, tSet);
        const qJacc = jaccard(qTokens, tSet);
        const bgOverlap = qBigrams.size ? overlapRatio(qBigrams, bSet) : 0;
        const ctxOverlap = overlapRatio(ctxTokens, tSet);
        const lenTokens = Math.max(1, contentTokens(text).length);
        const conciseSignal = Math.min(1, 18 / lenTokens);
        const analyticSignal =
          (/\b(step|first|second|third|because|therefore|verify)\b/i.test(text) ? 0.6 : 0) +
          (/^\s*\d+[.)]\s/m.test(text) ? 0.3 : 0);
        const creativeSignal =
          (/\b(creative|imagine|metaphor|analogy|story|vivid|brainstorm)\b/i.test(text) ? 0.55 : 0) +
          (/[;:]/.test(text) ? 0.12 : 0);
        const empathySignal = /\b(i understand|that sounds|no problem|it's okay|you’re not alone|you're not alone)\b/i.test(text) ? 0.4 : 0;
        let domain = 0;
        if (qDomains.code && /\b(code|debug|error|python|api|traceback|function|class)\b/i.test(text)) domain += 0.2;
        if (qDomains.science && /\b(science|physics|chemistry|biology|experiment|hypothesis)\b/i.test(text)) domain += 0.2;
        if (qDomains.math && /\b(math|algebra|equation|calculate|fraction|percent|solve)\b/i.test(text)) domain += 0.2;
        if (qDomains.english && /\b(grammar|rewrite|proofread|sentence|paragraph|essay)\b/i.test(text)) domain += 0.2;
        if (qDomains.scripture && /\b(bible|scripture|verse|chapter|psalm|gospel|kjv)\b/i.test(text)) domain += 0.2;
        if (qDomains.dictionary && /\b(definition|define|synonym|antonym|part of speech|meaning)\b/i.test(text)) domain += 0.2;
        if (qDomains.literary && /\b(novel|chapter|character|theme|tone|literary|joyce|finnegans)\b/i.test(text)) domain += 0.2;

        const countBonus = Math.min(0.22, Math.log1p(Math.max(1, c.count)) / 30);
        const prior = Number(state.meta?.labelPriors?.[c.label] ?? 0) || 0;
        const priorBonus = Math.min(0.08, prior * 0.08);
        const bucketBonus = Math.min(0.25, Math.max(0, Number(c.bucket_score || 0)) * 0.25);
        const repeatPenalty = recentSet.has(text) ? 0.45 : 0;
        const templatePenalty = isTemplateArtifact(text) ? (genericShort ? 0.8 : 0.25) : 0;
        const weirdPenalty = genericShort && /(?:\[[^\]]+\]|policy framing|youth populations)/i.test(text) ? 0.5 : 0;
        const convoBoost = genericShort && /\b(help|clarify|what|want|can|tell me)\b/i.test(text) ? 0.12 : 0;

        let score = 0.58 * ctxOverlap + 0.30 * qOverlap + 0.18 * qJacc + 0.22 * bgOverlap + domain + countBonus + priorBonus + bucketBonus + convoBoost;
        const mode = inferStyleMode(q, els.styleMode.value);
        if (mode === 'concise') score += 0.18 * conciseSignal - 0.05 * creativeSignal;
        else if (mode === 'analyst') score += 0.16 * analyticSignal + 0.05 * domain;
        else if (mode === 'creative') score += 0.16 * creativeSignal + 0.06 * Math.min(1, lenTokens / 32);
        else score += 0.08 * empathySignal + 0.06 * analyticSignal;

        score -= repeatPenalty + templatePenalty + weirdPenalty;

        scored.push({ ...c, score });
      }

      scored.sort((a, b) => b.score - a.score);
      return scored;
    }

    function chooseResponse(query, ranked) {
      if (!ranked.length) return 'I do not have a response loaded yet. Load metadata first.';
      const mode = inferStyleMode(query, els.styleMode.value);
      const creativity = Number(els.creativity.value || 0.5);
      const top = ranked.slice(0, Math.max(1, Math.min(Number(els.topK.value || 40), ranked.length)));

      let chosen = top[0];
      if (mode === 'creative' && creativity > 0.2) {
        const n = Math.min(5, top.length);
        const pool = top.slice(0, n);
        const temp = 0.35 + creativity * 0.8;
        const weights = pool.map(r => Math.exp(r.score / Math.max(0.15, temp)));
        const sum = weights.reduce((a,b) => a+b, 0) || 1;
        let x = Math.random() * sum;
        for (let i = 0; i < pool.length; i++) {
          x -= weights[i];
          if (x <= 0) { chosen = pool[i]; break; }
        }
      }

      return styleAdjust(chosen.text, query, mode, creativity);
    }

    async function fetchArrayBufferWithProgress(url, onProgress) {
      const res = await fetch(url, { cache: 'no-store' });
      if (!res.ok) throw new Error(`HTTP ${res.status} loading ${url}`);
      const totalHeader = Number(res.headers.get('content-length'));
      const total = Number.isFinite(totalHeader) && totalHeader > 0 ? totalHeader : null;
      if (!res.body || typeof res.body.getReader !== 'function') {
        const buf = await res.arrayBuffer();
        if (onProgress) onProgress(buf.byteLength, total || buf.byteLength);
        return buf;
      }

      const reader = res.body.getReader();
      const chunks = [];
      let received = 0;
      while (true) {
        const { done, value } = await reader.read();
        if (done) break;
        if (!value) continue;
        chunks.push(value);
        received += value.byteLength;
        if (onProgress) onProgress(received, total);
      }
      const out = new Uint8Array(received);
      let offset = 0;
      for (const chunk of chunks) {
        out.set(chunk, offset);
        offset += chunk.byteLength;
      }
      if (onProgress) onProgress(received, total || received);
      return out.buffer;
    }

    async function loadMetaFromUrl(url, onProgress) {
      const buf = await fetchArrayBufferWithProgress(url, onProgress);
      const text = new TextDecoder('utf-8').decode(new Uint8Array(buf));
      return JSON.parse(text);
    }

    function loadMetaFromFile(file, onProgress) {
      return new Promise((resolve, reject) => {
        const reader = new FileReader();
        reader.onload = () => {
          try { resolve(JSON.parse(reader.result)); }
          catch (e) { reject(e); }
        };
        reader.onprogress = (e) => {
          if (onProgress && e && e.lengthComputable) {
            onProgress(e.loaded, e.total);
          } else if (onProgress && e) {
            onProgress(e.loaded || 0, null);
          }
        };
        reader.onerror = () => reject(reader.error || new Error('File read failed'));
        reader.readAsText(file);
      });
    }

    async function apiRefreshStatus() {
      const d = await apiJson(apiUrl('/api/status'));
      const s = d.status || {};
      if (s.loaded) {
        setStatus(`Backend ready (${s.model_size || 'model'} on ${s.device || 'device'}).`, 'ok');
      } else {
        setStatus('Backend reachable, but no model is loaded yet.', 'warn');
      }
      return s;
    }

    async function loadFromApi() {
      const weights = String(els.apiWeights.value || '').trim();
      const meta = String(els.apiMeta.value || '').trim();
      if (!weights || !meta) {
        throw new Error('Enter both backend weights and metadata paths.');
      }
      setStatus('Loading full model on backend...', 'warn');
      const d = await apiJson(apiUrl('/api/load'), {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ weights, meta })
      });
      const status = d && d.loaded !== undefined ? d : null;
      if (status) {
        setStatus(`Full model loaded (${status.model_size || 'model'} on ${status.device || 'device'}).`, 'ok');
      } else {
        await apiRefreshStatus();
      }
      addMessage('sys', 'Backend full model loaded.');
    }

    async function sendViaApi(user) {
      const temp = Number(els.apiResponseTemp.value || 0.08);
      const showTop = Number(els.apiShowTop.value || 0);
      const d = await apiJson(apiUrl('/api/chat'), {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          session_id: state.apiSessionId,
          message: user,
          style_mode: els.styleMode.value,
          response_temperature: Number.isFinite(temp) ? temp : 0.08,
          show_top_responses: Number.isFinite(showTop) ? showTop : 0
        })
      });
      renderTopCandidates(Array.isArray(d.top_candidates) ? d.top_candidates : []);
      addMessage('bot', d.response || 'No response');
      if (d.timing_ms) {
        const t = d.timing_ms;
        addMessage('sys', `Timing: infer=${t.infer ?? '?'} ms | rank=${t.rank_pick ?? '?'} ms | total=${t.total ?? '?'} ms`);
      }
    }

    async function clearApiSession() {
      await apiJson(apiUrl('/api/clear'), {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ session_id: state.apiSessionId })
      });
    }

    async function loadArrayBufferFromUrl(url, onProgress) {
      return fetchArrayBufferWithProgress(url, onProgress);
    }

    function loadArrayBufferFromFile(file, onProgress) {
      return new Promise((resolve, reject) => {
        const reader = new FileReader();
        reader.onload = () => resolve(reader.result);
        reader.onprogress = (e) => {
          if (onProgress && e && e.lengthComputable) {
            onProgress(e.loaded, e.total);
          } else if (onProgress && e) {
            onProgress(e.loaded || 0, null);
          }
        };
        reader.onerror = () => reject(reader.error || new Error('File read failed'));
        reader.readAsArrayBuffer(file);
      });
    }

    function softmax(values) {
      const xs = Array.from(values || []);
      if (!xs.length) return [];
      let mx = -Infinity;
      for (const v of xs) if (v > mx) mx = v;
      const exps = xs.map(v => Math.exp(v - mx));
      const sum = exps.reduce((a, b) => a + b, 0) || 1;
      return exps.map(v => v / sum);
    }

    function onnxAvailableLabels(meta) {
      if (Array.isArray(meta?.availableLabels) && meta.availableLabels.length) {
        return meta.availableLabels.map(v => Number(v)).filter(Number.isFinite);
      }
      if (meta?.bucketsByLabel && typeof meta.bucketsByLabel === 'object') {
        return Object.keys(meta.bucketsByLabel).map(v => Number(v)).filter(Number.isFinite).sort((a, b) => a - b);
      }
      return Array.from({ length: 10 }, (_, i) => i);
    }

    function poolCandidatesFromOnnx(logitsVec, meta) {
      const labels = onnxAvailableLabels(meta);
      const labelLogits = labels.map(lbl => Number(logitsVec[lbl] ?? 0));
      const probs = softmax(labelLogits);
      const pooled = [];
      for (let i = 0; i < labels.length; i++) {
        const label = labels[i];
        const bucketScore = probs[i] ?? 0;
        const rows = meta?.bucketsByLabel?.[String(label)] || [];
        for (const row of rows) {
          pooled.push({
            label: String(label),
            text: String(row.text || ''),
            count: Number.isFinite(Number(row.count)) ? Number(row.count) : 1,
            bucket_score: bucketScore
          });
        }
      }
      const dedup = new Map();
      for (const row of pooled) {
        const text = String(row.text || '').trim();
        if (!text) continue;
        const prev = dedup.get(text);
        if (!prev) {
          dedup.set(text, { ...row, text });
          continue;
        }
        prev.count = (Number(prev.count) || 1) + (Number(row.count) || 1);
        prev.bucket_score = Math.max(Number(prev.bucket_score) || 0, Number(row.bucket_score) || 0);
      }
      return Array.from(dedup.values());
    }

    async function loadFromBrowserOnnx() {
      if (typeof ort === 'undefined' || !ort?.InferenceSession) {
        throw new Error('onnxruntime-web failed to load.');
      }
      if (!self.ChatFeatureCtxV2 || typeof ChatFeatureCtxV2.textToModelInput !== 'function') {
        throw new Error('ChatFeatureCtxV2 encoder not loaded.');
      }

      setStatus('Loading ONNX model + full metadata in browser...', 'warn');

      const onnxFile = els.onnxModelFile.files && els.onnxModelFile.files[0];
      const metaFile = els.onnxMetaFile.files && els.onnxMetaFile.files[0];
      const onnxSource = onnxFile ? onnxFile.name : String(els.onnxModelUrl.value || '').trim();
      const metaSource = metaFile ? metaFile.name : String(els.onnxMetaUrl.value || '').trim();
      if (!onnxSource) throw new Error('Provide an ONNX model file or URL.');
      if (!metaSource) throw new Error('Provide a full metadata JSON file or URL.');

      const onnxBytes = onnxFile
        ? await loadArrayBufferFromFile(onnxFile, (loaded, total) =>
            setPhaseByteProgress('Loading ONNX model', loaded, total ?? onnxFile.size ?? null, 0.00, 0.82))
        : await loadArrayBufferFromUrl(onnxSource, (loaded, total) =>
            setPhaseByteProgress('Downloading ONNX model', loaded, total, 0.00, 0.82));

      const rawMeta = metaFile
        ? await loadMetaFromFile(metaFile, (loaded, total) =>
            setPhaseByteProgress('Loading full metadata', loaded, total ?? metaFile.size ?? null, 0.82, 0.95))
        : await loadMetaFromUrl(metaSource, (loaded, total) =>
            setPhaseByteProgress('Downloading full metadata', loaded, total, 0.82, 0.95));

      setLoadProgress({
        label: 'Initializing ONNX runtime',
        fraction: 0.96,
        detail: 'Creating inference session...'
      });

      const meta = normalizeMeta(rawMeta);
      if (!meta.bucketsByLabel || !Object.keys(meta.bucketsByLabel).length) {
        throw new Error('Browser ONNX mode requires full metadata JSON with buckets.');
      }

      if (ort.env?.wasm) {
        ort.env.wasm.simd = true;
      }
      const session = await ort.InferenceSession.create(onnxBytes, { executionProviders: ['wasm'] });
      setLoadProgress({
        label: 'Finalizing browser ONNX',
        fraction: 1,
        detail: 'Model and metadata loaded.'
      });
      const featureMode = String(meta.featureMode || 'context_v2').toLowerCase();

      state.onnxSession = session;
      state.onnxMetaRaw = rawMeta;
      state.onnxModelSource = onnxSource;
      state.onnxFeatureMode = featureMode;
      state.meta = meta;
      state.candidates = meta.candidates;

      setStatus(`Browser ONNX loaded (${meta.modelSize || 'model'}, feature=${featureMode || 'context_v2'}).`, 'ok');
      addMessage('sys', `Browser ONNX ready. Model: ${onnxSource}. Metadata buckets: ${meta.stats.bucketCount}.`);
    }

    async function sendViaBrowserOnnx(user) {
      if (!state.onnxSession) {
        throw new Error('Load Browser ONNX mode first.');
      }
      if (!state.meta?.bucketsByLabel) {
        throw new Error('Full metadata with buckets is not loaded.');
      }

      const smallTalk = detectSmallTalk(user);
      if (smallTalk) {
        renderTopCandidates([]);
        addMessage('bot', smallTalk);
        state.history.push({ user, bot: smallTalk });
        state.recentAssistant.push(smallTalk);
        if (state.history.length > 20) state.history = state.history.slice(-20);
        if (state.recentAssistant.length > 8) state.recentAssistant = state.recentAssistant.slice(-8);
        return;
      }

      const t0 = performance.now();
      const tFeat0 = performance.now();
      let featureMode = String(state.onnxFeatureMode || 'context_v2').toLowerCase();
      if (featureMode !== 'context_v2' && featureMode !== 'legacy') {
        // Current generated encoder is exact for legacy + context_v2 (supermix v27 chat uses context_v2).
        featureMode = 'context_v2';
      }
      const ctx = ChatFeatureCtxV2.buildContext(state.history, user, 2);
      const featVec = ChatFeatureCtxV2.textToModelInput(ctx, featureMode);
      const featMs = performance.now() - tFeat0;

      const tInf0 = performance.now();
      const inputName = (state.onnxSession.inputNames && state.onnxSession.inputNames[0]) || 'x';
      const tensor = new ort.Tensor('float32', featVec, [1, 1, ChatFeatureCtxV2.FEAT_DIM]);
      const outputs = await state.onnxSession.run({ [inputName]: tensor });
      const outputName = (state.onnxSession.outputNames && state.onnxSession.outputNames[0]) || Object.keys(outputs)[0];
      const out = outputs[outputName];
      if (!out || !out.data) throw new Error('ONNX model returned no logits.');
      const logits = Array.from(out.data).slice(-ChatFeatureCtxV2.MODEL_CLASSES);
      const infMs = performance.now() - tInf0;

      const tRank0 = performance.now();
      const pooled = poolCandidatesFromOnnx(logits, state.meta);
      const ranked = rankCandidates(user, pooled);
      const bot = chooseResponse(user, ranked);
      renderTopCandidates(ranked.slice(0, 8));
      const rankMs = performance.now() - tRank0;
      const totalMs = performance.now() - t0;

      addMessage('bot', bot);
      addMessage('sys', `Timing: feat=${featMs.toFixed(1)} ms | infer=${infMs.toFixed(1)} ms | rank=${rankMs.toFixed(1)} ms | total=${totalMs.toFixed(1)} ms`);

      state.history.push({ user, bot });
      state.recentAssistant.push(bot);
      if (state.history.length > 20) state.history = state.history.slice(-20);
      if (state.recentAssistant.length > 8) state.recentAssistant = state.recentAssistant.slice(-8);
    }

    async function doLoad() {
      if (state.loading) return;
      state.loading = true;
      els.loadBtn.disabled = true;
      try {
        if (isApiMode()) {
          await loadFromApi();
          await apiRefreshStatus();
          if (!state.history.length) {
            addMessage('bot', 'Full model API mode is ready. Ask a question.');
          }
        } else if (isOnnxMode()) {
          await loadFromBrowserOnnx();
          if (!state.history.length) {
            addMessage('bot', 'Browser ONNX mode is ready. The full model weights are running on your device.');
          }
        } else {
          setStatus('Loading metadata...', 'warn');
          let raw;
          const file = els.metaFile.files && els.metaFile.files[0];
          if (file) {
            raw = await loadMetaFromFile(file, (loaded, total) =>
              setPhaseByteProgress('Loading metadata JSON', loaded, total ?? file.size ?? null, 0, 1));
          } else {
            raw = await loadMetaFromUrl(els.metaUrl.value.trim(), (loaded, total) =>
              setPhaseByteProgress('Downloading metadata JSON', loaded, total, 0, 1));
          }

          const meta = normalizeMeta(raw);
          state.meta = meta;
          state.candidates = meta.candidates;
          setStatus(`Loaded ${meta.stats.candidateCount} candidates across ${meta.stats.bucketCount} buckets.`, 'ok');
          addMessage('sys', `Loaded metadata. Candidates: ${meta.stats.candidateCount}.`);
          if (!state.history.length) {
            addMessage('bot', 'Static web chat is ready. Ask a question.');
          }
        }
      } catch (err) {
        console.error(err);
        setStatus(`Load failed: ${err.message || err}`, 'err');
      } finally {
        hideLoadProgress();
        els.loadBtn.disabled = false;
        state.loading = false;
      }
    }

    async function onSend() {
      const user = els.userInput.value.trim();
      if (!user) return;
      addMessage('user', user);
      els.userInput.value = '';

      if (isApiMode()) {
        try {
          await sendViaApi(user);
        } catch (err) {
          console.error(err);
          addMessage('bot', `API error: ${err.message || err}`);
          setStatus(`API error: ${err.message || err}`, 'err');
        }
        return;
      }
      if (isOnnxMode()) {
        try {
          await sendViaBrowserOnnx(user);
        } catch (err) {
          console.error(err);
          addMessage('bot', `Browser ONNX error: ${err.message || err}`);
          setStatus(`Browser ONNX error: ${err.message || err}`, 'err');
        }
        return;
      }

      if (!state.candidates.length) {
        const msg = 'Load a metadata JSON first.';
        addMessage('bot', msg);
        return;
      }

      const t0 = performance.now();
      const smallTalk = detectSmallTalk(user);
      let bot;
      let ranked = [];
      if (smallTalk) {
        bot = smallTalk;
      } else {
        ranked = rankCandidates(user);
        renderTopCandidates(ranked.slice(0, 8));
        bot = chooseResponse(user, ranked);
      }
      const dt = performance.now() - t0;

      addMessage('bot', bot);
      addMessage('sys', `Timing: ${dt.toFixed(1)} ms`);

      state.history.push({ user, bot });
      state.recentAssistant.push(bot);
      if (state.history.length > 20) state.history = state.history.slice(-20);
      if (state.recentAssistant.length > 8) state.recentAssistant = state.recentAssistant.slice(-8);
    }

    async function onClear() {
      clearChatUI();
      if (isApiMode()) {
        try {
          await clearApiSession();
          addMessage('sys', 'Backend session cleared.');
        } catch (err) {
          console.error(err);
          addMessage('bot', `Clear API error: ${err.message || err}`);
        }
      }
      if (isOnnxMode()) {
        addMessage('sys', 'Browser ONNX session state cleared (local only).');
      }
    }

    els.loadBtn.addEventListener('click', doLoad);
    els.clearBtn.addEventListener('click', onClear);
    els.sendBtn.addEventListener('click', onSend);
    els.runMode.addEventListener('change', () => {
      clearChatUI();
      applyModeUI();
    });
    els.userInput.addEventListener('keydown', (e) => {
      if (e.key === 'Enter' && !e.shiftKey) {
        e.preventDefault();
        onSend();
      }
    });

    clearChatUI();
    applyModeUI();
  </script>
</body>
</html>
